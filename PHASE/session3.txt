# Session 3: Introduction to MCMC in R (Computing Practical)
# 
# Note: anything following a # sign is a comment, and will be ignored by R
# (this should make it easier to cut and paste things)
#
#
# Example 1: sampling from an exponential distribution using MCMC
#
# 
# first: a few example lines of R

R
x = seq(from = 0, to = 10, length=20)
?seq    # to get help on any command in R you can type ?command
x       # to see what an object looks like, just type its name
y = exp(-x)
y       # note that y is a vector, because x is a vector
plot(x,y)
lines(x,y) #lines adds lines to an existing plot

#
# We will learn more R as we go along: ask questions if there is
# something you don't understand!
#
# Now: set up a target function we want to sample from
# In this case we are going to use the density of the exponential distribution
# (What follows is not the best way to do things, but I have tried
# to make it easy to follow for novice users)
#

target = function(x){
if(x<0){
return(0)}
else {
return( exp(-x))
}
}

#Try computing a couple of values

target(1)
target(-1)

# Next, we will program a Metropolis--Hastings scheme to sample
# from a distribution proportional to the target

x = rep(0,1000)
x[1] = 3     #this is just a starting value, which I've set arbitrarily to 3
for(i in 2:1000){
currentx = x[i-1]
proposedx = currentx + rnorm(1,mean=0,sd=1)
A = target(proposedx)/target(currentx) 
if(runif(1)<A){
x[i] = proposedx       # accept move with probabily min(1,A)
} else {
x[i] = currentx        # otherwise "reject" move, and stay where we are
}
}

# note that x is a realisation of a Markov Chain
# we can make a few plots of x:
plot(x) 
hist(x)
acf(x)

# We can wrap this up in a function to make things a bit neater,
# and make it easy to try changing starting values and proposal distributions
easyMCMC = function(niter, startval, proposalsd){
x = rep(0,niter)
x[1] = startval     
for(i in 2:niter){
currentx = x[i-1]
proposedx = rnorm(1,mean=currentx,sd=proposalsd) 
A = target(proposedx)/target(currentx)
if(runif(1)<A){
x[i] = proposedx       # accept move with probabily min(1,A)
} else {
x[i] = currentx        # otherwise "reject" move, and stay where we are
}
}
return(x)
}

#Now we'll run the MCMC scheme 3 times, 
#and look to see how similar the results are
z1=easyMCMC(1000,3,1)
z2=easyMCMC(1000,3,1)
z3=easyMCMC(1000,3,1)

plot(z1,type="l")
lines(z2,col=2)
lines(z3,col=3)


par(mfcol=c(3,1)) #rather odd command tells R to put 3 graphs on a single page
hist(z1)
hist(z2)
hist(z3)


# Exercises: use the function easyMCMC to explore the following:
# 1a) how do different starting values affect the MCMC scheme?  
# 1b) what is the effect of having a bigger/smaller proposal standard deviation?
# 1c) try changing the target function to the following
target = function(x){
return((x>0 & x <1) + (x>2 & x<3))
}
# What does this target look like?
# What happens if the proposal sd is too small here? (try eg 1 and 0.1)
#
#
# --------------------------------------------------------------
#
#
#
# Example 2: Estimating an allele frequency
#
# A standard assumption when modelling genotypes of
# bi-allelic loci (eg loci with alleles A and a) is
# that the population is "randomly mating". From this assumption
# it follows that the population will be in 
# "Hardy Weinberg Equilibrium" (HWE), which means that 
# if p is the frequency of the allele A then the
# genotypes AA, Aa and aa will have frequencies
# p*p, 2p(1-p) and (1-p)*(1-p)
#
# A simple prior for p is to assume it is uniform on [0,1].
# Suppose that we sample n individuals, and observe nAA with genotype AA,
# nAa with genotype Aa and naa with genotype aa. 

# The following R code gives a short MCMC routine to sample from the posterior
# distribution of p. Try to go through the code to see how it works.

prior = function(p){
if((p<0) || (p>1)){  # || here means "or"
return(0)}
else{
return(1)}
}

likelihood = function(p, nAA, nAa, naa){
return(p^(2*nAA) * (2*p*(1-p))^nAa * (1-p)^(2*naa))
}

psampler = function(nAA, nAa, naa, niter, pstartval, pproposalsd){
p = rep(0,niter)
p[1] = pstartval
for(i in 2:niter){
currentp = p[i-1]
newp = currentp + rnorm(1,0,pproposalsd)
A = prior(newp)*likelihood(newp,nAA,nAa,naa)/(prior(currentp) * likelihood(currentp,nAA,nAa,naa))
if(runif(1)<A){
p[i] = newp       # accept move with probabily min(1,A)
} else {
p[i] = currentp        # otherwise "reject" move, and stay where we are
}
}
return(p)
}

# running this sample for nAA = 50, nAa = 21, naa=29.

z=psampler(50,21,29,10000,0.5,0.01)

# Now some R code to compare the sample from the posterior
# with the theoretical posterior (which in this case is available analytically;
# from lecture 1, since we observed 121 As, and 79 as, out of 200, the posterior
# for p is beta(121+1,79+1). See notes from Session 1.

x=seq(0,1,length=1000)
hist(z,prob=T)
lines(x,dbeta(x,122, 80))  # overlays beta density on histogram

# You might also like to discard the first 5000 z's as "burnin"
# here's one way in R to select only the last 5000 zs

hist(z[5001:10000])

#
#
# Some things to try: how do the starting point and proposal sd affect things?
#
#
# Example 3: Estimating an allele frequency and inbreeding coefficient
# (If time allows!)
#
# A slightly more complex alternative than HWE is to assume that
# there is a tendency for people to mate with others who are 
# slightly more closely-related than "random" (as might
# happen in a geographically-structured population, for example).
# This will result in an excess of homozygotes compared with
# HWE. A simple way to capture this is to introduce an extra parameter,
# the "inbreeding coefficient" f, and assume that the genotypes
# AA, Aa and aa have frequencies fp + (1-f)p*p, (1-f) 2p(1-p)
# and f(1-p) + (1-f)(1-p)(1-p)
#
# In most cases it would be natural to treat f as a feature of
# the population, and therefore assume f is constant across loci.
# For simplicity we will consider just a single locus.

# Note that both f and p are constrained to lie between 0 and 1
# (inclusive). A simple prior for each of these two parameters is to assume
# that they are independent, uniform on [0,1]. Suppose
# that we sample n individuals, and observe nAA with genotype AA,
# nAa with genotype Aa and naa with genotype aa. 
#
# Exercise: write a short MCMC routine to sample from the joint
# distribution of f and p.
# 
# Hint: here is a start; you'll need to fill in the ...
# 
fpsampler = function(nAA, nAa, naa, niter, fstartval, pstartval, fproposalsd, pproposalsd){
f = rep(0,niter)
p = rep(0,niter)
f[1] = fstartval
p[1] = pstartval
for(i in 2:niter){
currentf = f[i-1]
currentp = p[i-1]
newf = ...
newp = ...
...
...
}
return(list(f=f,p=p)) # return a "list" with two elements named f and p
}










